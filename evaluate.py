import nltk
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
from rouge_score import rouge_scorer

def evaluate_model(generated_text, reference_text):
    """
    Evaluates the generated text using ROUGE and BLEU scores.
    
    Parameters:
        generated_text (str): The text generated by the GPT-2 model.
        reference_text (str): The ground truth/reference text.

    Returns:
        dict: A dictionary containing ROUGE-1, ROUGE-2, ROUGE-L, and BLEU scores.
    """
    
    # Initialize ROUGE scorer
    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)
    rouge_scores = scorer.score(generated_text, reference_text)
    
    # Compute BLEU score
    smoothing = SmoothingFunction()
    reference_tokens = [nltk.word_tokenize(reference_text)]  # BLEU expects a list of reference tokens
    generated_tokens = nltk.word_tokenize(generated_text)
    bleu_score = sentence_bleu(reference_tokens, generated_tokens, smoothing_function=smoothing.method1)
    
    # Return scores in a dictionary
    return {
        'ROUGE-1': rouge_scores['rouge1'].fmeasure,
        'ROUGE-2': rouge_scores['rouge2'].fmeasure,
        'ROUGE-L': rouge_scores['rougeL'].fmeasure,
        'BLEU': bleu_score
    }